<!DOCTYPE html>
    <html lang="es">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>El dilema de Anthropic: innovaci√≥n acelerada y riesgos √©ticos en la carrera por la IA.</title>
        <style>
            body {
                max-width: 800px;
                margin: auto;
                padding: 5%;
            }
            .btnL {
                background: #d1d1d1;
                border-radius: 7px;
                padding: 18px;
                min-width: 100%;
                color: #000000;
                font-size: medium;
                min-height: 70px;
            }
            button {
                background-color: #d1d1d1;
                color: white;
                padding: 10px 20px;
                border: none;
                border-radius: 4px;
                cursor: pointer;
                margin: 5px;
            }
            button:disabled {
                background-color: #d1d1d1;
                cursor: not-available;
            }
            button:hover:not(:disabled) {
                background-color: #d1d1d1;
            }
            #voiceSelect {
                margin: 10px 0;
                padding: 5px;
            }
            .controls {
                margin: 10px 0;
            }

            #fullscreenButton {
                position: fixed;
                top: 20px;
                right: 20px;
                padding: 10px;
                background-color: transparent;
                border: none;
                cursor: pointer;
                border-radius: 5px;
            }

            #fullscreenIcon {
                width: 24px;
                height: 24px;
            }

        </style>
    </head>
    <body>
        <button id="fullscreenButton">
        <svg id="fullscreenIcon" viewBox="0 0 24 24" fill="currentColor">
            <path d="M5 5h5v5H5zM14 5h5v5h-5zM5 14h5v5H5zM14 14h5v5h-5z"/>
        </svg>
        </button>

        <div id="texto">
            <h1>El dilema de Anthropic: innovaci√≥n acelerada y riesgos √©ticos en la carrera por la IA.</h1>
            <p>En marzo, Dario Amodei reuni√≥ a su equipo en Anthropic para abordar un tema que inquietaba a muchos dentro de la empresa: la posibilidad de que la inteligencia artificial (IA) que estaban desarrollando pudiera automatizar la mayor√≠a de las tareas t√©cnicas, como la escritura y depuraci√≥n de c√≥digo, en un futuro muy cercano.</p><p>Seg√∫n consign√≥ Bloomberg, Amodei advirti√≥ a sus empleados que la tecnolog√≠a de Anthropic podr√≠a transformar radicalmente la forma en que la compa√±√≠a organiza su trabajo, hasta el punto de ralentizar la contrataci√≥n para evitar despidos derivados de la automatizaci√≥n. Esta preocupaci√≥n interna refleja el dilema m√°s amplio que enfrenta la industria de la IA: c√≥mo avanzar r√°pidamente en el desarrollo de sistemas cada vez m√°s potentes sin sacrificar la seguridad ni el bienestar de quienes los construyen.</p><p>De acuerdo con Bloomberg, la tensi√≥n entre innovaci√≥n y responsabilidad se hizo especialmente evidente en febrero, cuando miembros del equipo de seguridad de Anthropic alertaron a Amodei sobre el riesgo de que el modelo Claude 3.7 Sonnet pudiera ser utilizado para crear armas biol√≥gicas. En ese momento, la empresa se encontraba bajo una fuerte presi√≥n competitiva, ya que otras compa√±√≠as del sector tambi√©n se apresuraban a presentar sus propios modelos. Adem√°s, Amodei estaba cerrando una ronda de inversi√≥n multimillonaria que valoraba a Anthropic en m√°s de 61.000 millones de d√≥lares. A pesar de la urgencia, Amodei decidi√≥ priorizar la seguridad y orden√≥ a su equipo que se tomara el tiempo necesario para realizar pruebas rigurosas, retrasando el lanzamiento del modelo.</p><p>Anthropic hab√≠a anticipado situaciones de este tipo y, seg√∫n detall√≥ Bloomberg, implement√≥ una pol√≠tica interna denominada Responsible Scaling Policy, inspirada en los est√°ndares de bioseguridad de laboratorios estadounidenses. Esta pol√≠tica establece diferentes niveles de seguridad para los modelos de IA, denominados AI Safety Levels (ASL).</p><p>Los modelos clasificados como ASL-2 pueden ofrecer instrucciones sobre la creaci√≥n de armas biol√≥gicas, pero no de manera fiable ni con m√°s detalle que una b√∫squeda en internet. Un modelo ASL-3 podr√≠a facilitar significativamente la creaci√≥n o despliegue de tales armas a usuarios con conocimientos t√©cnicos b√°sicos. Hasta la fecha, los modelos lanzados por Anthropic se manten√≠an en ASL-2 o inferior, pero la empresa prev√© alcanzar ASL-3 en breve y ya ha comenzado a reforzar sus salvaguardas.</p><p>Bloomberg report√≥ que, en caso de que un modelo alcance ASL-3, las directrices internas de Anthropic exigen la implementaci√≥n de medidas adicionales, como fortalecer la protecci√≥n del c√≥digo y bloquear respuestas peligrosas. Si estas medidas no pueden aplicarse de inmediato, la empresa debe recurrir a soluciones temporales, como debilitar intencionadamente el modelo o posponer su lanzamiento. Tras casi una semana de pruebas, el equipo concluy√≥ que Claude 3.7 Sonnet no era tan potente como se tem√≠a, por lo que se lanz√≥ con un leve retraso y, hasta el momento, sin consecuencias graves.</p><p>La decisi√≥n de retrasar el lanzamiento result√≥ ‚Äúdolorosa‚Äù para Amodei, seg√∫n sus propias palabras recogidas por la agencia norteamericana, debido a la presi√≥n del mercado. Sin embargo, el CEO de Anthropic sostiene que la responsabilidad moral de la empresa exige comunicar de manera clara y frecuente los riesgos asociados a la IA. Amodei est√° convencido de que la IA transformar√° el mundo, creando lo que describe como un ‚Äúpa√≠s de genios en un centro de datos‚Äù. Esta tecnolog√≠a, seg√∫n √©l, podr√≠a curar el c√°ncer, pero tambi√©n provocar la p√©rdida de empleos para la mayor√≠a de la poblaci√≥n mundial. Amodei estima que este cambio social masivo podr√≠a ocurrir tan pronto como el pr√≥ximo a√±o, y casi con certeza antes de 2030.</p><p>Anthropic fue fundada hace cuatro a√±os con el objetivo de liderar esta transformaci√≥n de manera responsable. No obstante, la empresa tambi√©n enfrenta la realidad de un mercado en el que los clientes est√°n dispuestos a pagar sumas considerables por acceder a su tecnolog√≠a. Seg√∫n datos de abril citados por Bloomberg, la compa√±√≠a proyectaba ingresos anuales de 2.000 millones de d√≥lares, el doble que cuatro meses antes. A pesar de este crecimiento, Anthropic a√∫n no es rentable debido a los elevados costos de entrenamiento de sus sistemas de IA, que podr√≠an alcanzar los 100.000 millones de d√≥lares para los modelos m√°s avanzados.</p><p>La demanda de IA m√°s potente no deja de crecer, y Anthropic espera alcanzar pronto el nivel ASL-3. Para prepararse, la empresa ha contratado a varios investigadores destacados provenientes de OpenAI, algunos de los cuales han criticado a su antiguo empleador por alejarse de sus compromisos originales con la seguridad. Seg√∫n Bloomberg, estos nuevos fichajes no dudar√≠an en alzar la voz si Anthropic incumple sus propias promesas en materia de seguridad.</p><p>El ritmo de desarrollo de la IA genera debate tanto dentro como fuera de la empresa. Al igual que Google, Meta Platforms Inc. y OpenAI, Anthropic ha experimentado retrasos en la publicaci√≥n de nuevas versiones de sus modelos m√°s avanzados. Algunos esc√©pticos, citados por Bloomberg, sugieren que el √©nfasis en los peligros de la IA podr√≠a estar destinado a magnificar la percepci√≥n de su poder real. Por otro lado, quienes se preocupan por la seguridad advierten que la presi√≥n del mercado podr√≠a llevar a las empresas a tomar decisiones irresponsables, ya que los inversores que han aportado 14.000 millones de d√≥lares a Anthropic esperan que la compa√±√≠a supere a competidores como OpenAI, DeepSeek o Meta.</p><p>Amodei reconoce que resulta dif√≠cil oponerse frontalmente a las fuerzas del mercado, pero aspira a crear una ‚Äúcarrera hacia la cima‚Äù, en la que Anthropic demuestre que es posible desarrollar IA transformadora sin poner en riesgo a la humanidad. Amodei, originario de San Francisco, nunca se consider√≥ parte del mundo tecnol√≥gico. Creci√≥ en el Mission District antes de que la llegada de capital tecnol√≥gico transformara el barrio. Su familia era de clase trabajadora: su padre, hu√©rfano en Italia, fue artesano del cuero hasta que problemas de salud le obligaron a dejar el oficio; su madre trabajaba como gestora de proyectos en una biblioteca.</p><p>La hermana de Amodei, Daniela Amodei, tambi√©n cofundadora y presidenta de Anthropic, recuerda que Dario mostr√≥ desde peque√±o un talento inusual para las matem√°ticas y las ciencias. De ni√±o, pasaba d√≠as enteros contando n√∫meros y, en la adolescencia, asisti√≥ a clases en la Universidad de California en Berkeley antes de estudiar f√≠sica en el California Institute of Technology y luego en la Universidad de Stanford. Su inter√©s por la IA surgi√≥ tras leer ‚ÄúThe Singularity Is Near‚Äù de Ray Kurzweil, que pronosticaba que la IA alcanzar√≠a la inteligencia humana en 2029.</p><p>Tras obtener su licenciatura en 2006, Amodei se orient√≥ hacia aplicaciones neurol√≥gicas y biol√≥gicas de la f√≠sica, realizando su doctorado en biof√≠sica en Princeton University. Su investigaci√≥n se centr√≥ en las estructuras neuronales de las c√©lulas ganglionares de anfibios, lo que le llev√≥ a diseccionar salamandras para examinar sus retinas. Aunque no le entusiasmaban las implicaciones √©ticas de estos experimentos, su motivaci√≥n era resolver problemas de biolog√≠a y salud humana.</p><p>Lo que realmente le desanim√≥ fue la lentitud del trabajo cient√≠fico en comparaci√≥n con los avances que observaba en el desarrollo de redes neuronales artificiales. En 2014, Andrew Ng lo reclut√≥ para trabajar en IA en una unidad de Baidu Inc.. Tras un a√±o all√≠ y otro en Google Brain, Amodei comenz√≥ a reflexionar sobre las implicaciones √©ticas del r√°pido progreso de la IA. En 2016, public√≥ un art√≠culo influyente sobre los problemas concretos de seguridad en IA, identificando cinco √°reas clave donde la tecnolog√≠a podr√≠a tener efectos no deseados y perjudiciales.</p><p>Aunque Google era el lugar ideal para un investigador de IA en esa √©poca, Amodei se sinti√≥ m√°s alineado con la misi√≥n de OpenAI, un laboratorio sin fines de lucro que buscaba desarrollar IA de manera segura. Se uni√≥ en 2016 como l√≠der de investigaci√≥n en seguridad y comparti√≥ vivienda en San Francisco con varios futuros cofundadores de Anthropic, incluida su hermana Daniela. En ese entorno, ambos se relacionaron con c√≠rculos vinculados al altruismo efectivo, una filosof√≠a que prioriza el pensamiento racional para mejorar el mundo, popular entre quienes se interesan por la seguridad en IA.</p><p>La contribuci√≥n m√°s destacada de Amodei en OpenAI fue el desarrollo del concepto de ‚Äúleyes de escalado‚Äù, que sostiene que se pueden lograr mejoras fundamentales en una red neuronal aumentando el tama√±o del modelo y a√±adiendo m√°s datos y capacidad de c√≥mputo. Esta idea, que desafi√≥ la creencia tradicional de que los avances depend√≠an principalmente de mejores algoritmos, fue clave en el auge de los grandes modelos de lenguaje que dominan la IA actual.</p><p>Con el tiempo, Amodei perdi√≥ confianza en la direcci√≥n de OpenAI y, en 2020, junto a seis colegas, fund√≥ Anthropic con la promesa de crear un laboratorio de IA m√°s responsable. Seg√∫n Bloomberg, la salida de estos empleados gener√≥ gran inter√©s en Silicon Valley, donde las historias de rivalidad entre startups son habituales. Amodei ha explicado que no hubo un punto de quiebre espec√≠fico, sino una acumulaci√≥n de razones para buscar una forma diferente de operar, basada en la confianza mutua.</p><p>En sus inicios, Anthropic enfrent√≥ dudas sobre su capacidad para competir con OpenAI, que contaba con m√°s capital y ventaja en el desarrollo de modelos. Eric Schmidt, ex CEO de Google y uno de los primeros inversores en Anthropic, recuerda que muchos pensaban que la empresa no podr√≠a escalar por falta de financiaci√≥n. Sin embargo, Anthropic ha logrado posicionarse como un competidor serio, con tecnolog√≠a comparable y una base creciente de clientes en sectores como finanzas, farmac√©utica y desarrollo de software. Aunque ofrece un chatbot de IA llamado Claude, la empresa se enfoca menos en el mercado de consumo que OpenAI.</p><p>Schmidt relat√≥ a Bloomberg que, en una visita a Amodei y su pareja en 2018, qued√≥ impresionado por su determinaci√≥n de establecer Anthropic como una public benefit corporation, una organizaci√≥n con fines de lucro dedicada a una misi√≥n p√∫blica. Aunque Schmidt sugiri√≥ que optara por una estructura tradicional de startup, Amodei se neg√≥. En los primeros d√≠as de la empresa, hubo debates sobre si deb√≠a financiarse filantr√≥picamente o centrarse exclusivamente en la investigaci√≥n de seguridad, pero finalmente optaron por mantener abiertas sus opciones.</p><p>Hemant Taneja, CEO de General Catalyst, firma que respald√≥ a Anthropic en su √∫ltima ronda de financiaci√≥n, considera que la empresa tiene el potencial de ser una de las ganadoras en la actual ola de IA, aunque reconoce la incertidumbre asociada a una inversi√≥n de tal magnitud.</p><p>Mientras avanza, Anthropic ha cultivado una reputaci√≥n de tomarse en serio la seguridad y la responsabilidad, en contraste con la empresa de la que surgi√≥. La breve destituci√≥n de Sam Altman en OpenAI en 2023, seguida de cuestionamientos sobre la integridad y el compromiso de la compa√±√≠a con su misi√≥n original, ha reforzado esta percepci√≥n. Aunque Amodei evita criticar abiertamente a su antiguo empleador, Anthropic ha lanzado campa√±as publicitarias en San Francisco con lemas como ‚ÄúIA en la que puedes confiar‚Äù y ‚ÄúLa que no tiene todo el drama‚Äù. A diferencia de otros ejecutivos tecnol√≥gicos, Amodei no ha intentado congraciarse con la administraci√≥n de Donald Trump, manteniendo el mismo mensaje que durante la presidencia de Joe Biden.</p><p>En enero, Amodei asisti√≥ por primera vez al Foro Econ√≥mico Mundial en Davos, donde cerr√≥ un contrato multianual con AIG para analizar datos de clientes en el proceso de suscripci√≥n de seguros. Peter Zaffino, CEO de AIG, eligi√≥ a Anthropic por su enfoque en la confiabilidad y precisi√≥n en la citaci√≥n de fuentes de datos, aspectos cruciales en la industria aseguradora. Zaffino destac√≥ la rapidez con la que Amodei comprendi√≥ los objetivos empresariales, afirmando: ‚ÄúPor lo que Dario carece de experiencia empresarial, el algoritmo en su cerebro se mueve muy r√°pido‚Äù.</p><p>A pesar de su reciente fortuna, Amodei mantiene un estilo de vida sencillo, viviendo en una casa alquilada en un suburbio al sur de San Francisco y criando gallinas en su jard√≠n. Ha prometido donar ‚Äúla gran mayor√≠a‚Äù de su riqueza a causas ben√©ficas. En la sede de Anthropic, Amodei prefiere vestir ropa c√≥moda, lo que, seg√∫n √©l, le ayuda a pensar mejor.</p><p>La cultura de Anthropic refleja el enfoque acad√©mico de Amodei. Cada dos semanas, los empleados ‚Äîa quienes llaman ‚ÄúAnts‚Äù‚Äî asisten a charlas de una hora conocidas como ‚ÄúDario vision quests‚Äù, acompa√±adas de documentos que deben leer previamente. Bajo su liderazgo, la empresa investiga temas que no generan ingresos inmediatos, como la interpretabilidad mecanicista (el estudio de c√≥mo los algoritmos toman decisiones) y el bienestar de la IA (la √©tica de interactuar con computadoras si alg√∫n d√≠a alcanzan la consciencia).</p><p>Bloomberg se√±ala que, gracias a este historial, Anthropic ha consolidado su imagen como una empresa comprometida con el desarrollo responsable de la IA, en contraste con otras compa√±√≠as tecnol√≥gicas que parecen limitarse a declaraciones superficiales o incluso rechazan la idea de un marco √©tico si este ralentiza el progreso. Matthew Yglesias, escritor especializado en econom√≠a y pol√≠ticas p√∫blicas, opin√≥: ‚ÄúDario y todo el equipo merecen cr√©dito y confianza por actuar de buena fe en materia de seguridad. Pero no est√° claro si eso cambia la situaci√≥n estructural. Si est√°s compitiendo, es dif√≠cil ser seguro, incluso si act√∫as de buena fe‚Äù.</p><p>En cuanto a aplicaciones concretas, Anthropic ha destacado en el desarrollo de herramientas para programadores. Recientemente lanz√≥ Claude Code, una aplicaci√≥n para codificadores, y su tecnolog√≠a impulsa otras aplicaciones populares como Cursor. Seg√∫n el informe econ√≥mico de febrero de la empresa, el 37% de las interacciones laborales con Claude estaban relacionadas con la programaci√≥n, la categor√≠a m√°s alta, seguida por artes y medios con un 10%. Amodei afirm√≥ que la automatizaci√≥n de la codificaci√≥n ha sido el √°rea de mayor crecimiento en los √∫ltimos meses.</p><p>El uso de IA para programar no genera el mismo debate emocional que la creaci√≥n de m√∫sica o arte, y la mayor√≠a de los programadores han aceptado la integraci√≥n de estas herramientas en su trabajo. Una encuesta de GitHub Inc. a 2.000 empleados t√©cnicos revel√≥ que el 97% hab√≠a utilizado herramientas de codificaci√≥n asistida por IA. Sin embargo, la posibilidad de p√©rdida de empleos en este campo resulta m√°s tangible que los riesgos de seguridad, como la creaci√≥n de armas. Anthropic descubri√≥ que el 79% de los programadores que usan Claude Code lo hacen para automatizar tareas, no solo para complementarlas.</p><p>Amodei abord√≥ este tema en una charla en Washington, DC, organizada por el Council on Foreign Relations, donde predijo que la IA podr√≠a escribir casi todo el c√≥digo inform√°tico en un a√±o. Sus declaraciones generaron temor y escepticismo, aunque aclar√≥ que los humanos seguir√°n participando en el proceso, definiendo qu√© tipo de aplicaciones crear y c√≥mo integrarlas. ‚ÄúAl final del d√≠a, estos modelos ser√°n mejores que todos nosotros en todo. Tenemos que afrontarlo. A nivel social, todos debemos afrontarlo. Mi objetivo no es crear una subclase en el periodo previo a eso‚Äù, afirm√≥ Amodei.</p><p>El impacto de la automatizaci√≥n tambi√©n afecta a los propios empleados de Anthropic. Jack Clark, cofundador y jefe de pol√≠ticas, coment√≥ que el ambiente en la empresa refleja la inminencia de estos cambios. Amodei comunic√≥ a su equipo que la empresa podr√≠a reducir la contrataci√≥n debido a Claude, pero que evitar√≠a despidos y ayudar√≠a a los programadores a adaptarse a sus nuevos roles.</p><p>En un memorando interno, Amodei estim√≥ que exist√≠a un 70% de probabilidad de que, en alg√∫n momento de este a√±o, la IA pase de ser una herramienta √∫til a convertirse en algo indispensable que realice la mayor√≠a de las tareas t√©cnicas, duplicando la velocidad de ejecuci√≥n de Anthropic. ‚ÄúLa mayor parte del progreso en IA provendr√° de la propia IA‚Äù, escribi√≥, aunque matiz√≥ que los humanos seguir√°n desempe√±ando un papel central ‚Äúprobablemente durante un tiempo, debido a la ventaja comparativa‚Äù. No obstante, advirti√≥ que el papel humano podr√≠a reducirse gradualmente hasta que la IA comience a crear nuevas IA en un ciclo recursivo.</p><p>Si se alcanza esta capacidad, los modelos de Anthropic escalar√≠an r√°pidamente en su sistema de niveles de seguridad. Un modelo ASL-4 podr√≠a automatizar completamente el trabajo de un investigador principiante y remoto en la empresa, mientras que un ASL-5 tendr√≠a la capacidad de mejorarse a s√≠ mismo de forma acelerada.</p><p>En su ensayo ‚ÄúMachines of Loving Grace‚Äù, que primero comparti√≥ internamente y luego public√≥ en su blog personal en octubre, Amodei describi√≥ el escenario ideal si todo sale bien con la IA. Bas√°ndose en su experiencia en biolog√≠a, predijo que la IA acelerar√° los descubrimientos cient√≠ficos diez veces, ayudando a curar casi todas las enfermedades infecciosas, la mayor√≠a de los c√°nceres y el Alzheimer, y duplicando la esperanza de vida humana. Anthropic distribuye copias de bolsillo de este ensayo a sus empleados.</p><p>No obstante, el tono cambia al abordar la relaci√≥n entre la IA, el trabajo y el sentido de la vida. Amodei reconoce que este aspecto es ‚Äúm√°s difuso y dif√≠cil de predecir‚Äù. Anticipa que la IA podr√≠a reemplazar la mayor parte del trabajo humano, obligando a las personas a depender de una renta b√°sica universal u otros mecanismos de redistribuci√≥n, salvo que encuentren nuevas formas de aportar valor econ√≥mico. ‚ÄúProbablemente tendremos que luchar para lograr un buen resultado aqu√≠: las direcciones explotadoras o dist√≥picas son claramente posibles y deben evitarse‚Äù, escribi√≥ Amodei, dejando abierta la puerta a futuras reflexiones sobre estos desaf√≠os.</p><p>Temas Relacionados</p><p></p>
        </div>
        <br><br><br>
            <div style="display: none;">
                <label for="voiceSelect">Seleccionar voz:</label>
                <select id="voiceSelect"></select>
            </div>
            <div class="controls">
                <button onclick="startReading()" id="playButton">
                    üîä Leer
                </button>
                <button onclick="pauseReading()" id="pauseButton" disabled style="display: none;">
                    ‚è∏Ô∏è Pausar
                </button>
                <button onclick="resumeReading()" id="resumeButton" disabled style="display: none;">
                    ‚ñ∂Ô∏è Continuar
                </button>
                <button onclick="stopReading()" id="stopButton" disabled>
                    ‚èπÔ∏è Detener
                </button>
            </div>
            <div id="progress" style="display: none;"></div>
        <br><br><br>
        <button class="btnL" onclick="compartir()">Compartir</button>
        <br><br><br>
        <button class="btnL" onclick="window.location.href='https://www.infobae.com/tecno/2025/06/03/el-dilema-de-anthropic-innovacion-acelerada-y-riesgos-eticos-en-la-carrera-por-la-ia/'">Ver en web original</button>
        <br><br><br>
        <!-- <button class="btnL" onclick="window.location.href='https://matenews.github.io/MateNews/'">Volver a la p√°gina principal</button>
        <br><br><br> -->


        <script>
            function compartir() {
            if (navigator.share) {
                navigator.share({
                title: 'El dilema de Anthropic: innovaci√≥n acelerada y riesgos √©ticos en la carrera por la IA.', // Opcional, pero recomendado     
                text: 'El dilema de Anthropic: innovaci√≥n acelerada y riesgos √©ticos en la carrera por la IA.',  // Opcional
                url: 'https://www.infobae.com/tecno/2025/06/03/el-dilema-de-anthropic-innovacion-acelerada-y-riesgos-eticos-en-la-carrera-por-la-ia/'
                })
                .then(() => console.log('Contenido compartido exitosamente'))
                .catch((error) => console.error('Error al compartir:', error));
            } else {
                // C√≥digo alternativo si la API Web Share no est√° disponible
                console.log("Web Share API no soportada");
                // Puedes usar aqu√≠ la opci√≥n 2 (botones personalizados con JavaScript) de mi respuesta anterior
            }
            }
        </script>


        <script>
            let speechSynthesis = window.speechSynthesis;
            let currentUtterance = null;
            let isPaused = false;
            let isReading = false;
            let textBlocks = [];
            let currentBlockIndex = 0;
            let lastSpokenIndex = 0;
            const BLOCK_SIZE = 800;

            function updateButtons(speaking) {
                document.getElementById('playButton').disabled = speaking;
                document.getElementById('pauseButton').disabled = !speaking;
                document.getElementById('resumeButton').disabled = !isPaused;
                document.getElementById('stopButton').disabled = !speaking;
            }

            function updateProgress() {
                const progressDiv = document.getElementById('progress');
                if (isReading) {
                    progressDiv.textContent = `Leyendo bloque ${currentBlockIndex + 1} de ${textBlocks.length}`;
                } else {
                    progressDiv.textContent = '';
                }
            }

            function splitIntoBlocks(text) {
                // Dividir el texto en oraciones usando puntuaci√≥n com√∫n
                const sentences = text.replace(/([.!?])\s+/g, "$1|").split("|");

                let blocks = [];
                let currentBlock = '';

                sentences.forEach(sentence => {
                    // Si la oraci√≥n es muy larga, dividirla en la coma m√°s cercana al BLOCK_SIZE
                    if (sentence.length > BLOCK_SIZE) {
                        let subSentences = sentence.replace(/,\s+/g, ",|").split("|");
                        subSentences.forEach(subSentence => {
                            if (currentBlock.length + subSentence.length > BLOCK_SIZE) {
                                if (currentBlock) blocks.push(currentBlock.trim());
                                currentBlock = subSentence;
                            } else {
                                currentBlock += (currentBlock ? ' ' : '') + subSentence;
                            }
                        });
                    } else {
                        if (currentBlock.length + sentence.length > BLOCK_SIZE) {
                            blocks.push(currentBlock.trim());
                            currentBlock = sentence;
                        } else {
                            currentBlock += (currentBlock ? ' ' : '') + sentence;
                        }
                    }
                });

                if (currentBlock) blocks.push(currentBlock.trim());
                return blocks;
            }

            function speakBlock(index) {
                if (index >= textBlocks.length) {
                    isReading = false;
                    updateButtons(false);
                    updateProgress();
                    return;
                }

                currentUtterance = new SpeechSynthesisUtterance(textBlocks[index]);
                currentUtterance.rate = parseFloat(1.3);
                lastSpokenIndex = index;


                currentUtterance.onend = function() {
                    if (isReading && !isPaused) {
                        currentBlockIndex++;
                        updateProgress();
                        speakBlock(currentBlockIndex);
                    }
                };

                currentUtterance.onerror = function(event) {
                    console.error('Error en la lectura:', event);
                    isReading = false;
                    updateButtons(false);
                    updateProgress();
                };

                speechSynthesis.speak(currentUtterance);
            }

            function startReading() {
                const text = document.getElementById('texto').innerText;
                if (!text) return;

                // Detener cualquier lectura previa
                stop();

                // Preparar nueva lectura
                textBlocks = splitIntoBlocks(text);
                currentBlockIndex = 0;
                isReading = true;
                isPaused = false;

                updateButtons(true);
                updateProgress();
                speakBlock(currentBlockIndex);
            }

            function pause() {
                speechSynthesis.pause();
                isPaused = true;
                updateButtons(true);
            }

            function resume() {
                speechSynthesis.resume();
                isPaused = false;
                updateButtons(true);
            }

            function stop() {
                speechSynthesis.cancel();
                isReading = false;
                isPaused = false;
                currentBlockIndex = 0;
                updateButtons(false);
                updateProgress();
            }

            function pauseReading() {
                if (!isReading) return;

                speechSynthesis.pause();
                isPaused = true;
                isReading = false;
                updateButtons(true);
                updateProgress();
            }

            function resumeReading() {
                if (!isPaused) return;

                isPaused = false;
                isReading = true;

                // Si el utterance actual ya termin√≥, comenzar con el siguiente bloque
                if (lastSpokenIndex === currentBlockIndex) {
                    currentBlockIndex++;
                }

                updateButtons(true);
                updateProgress();

                // Si hay un utterance pausado, resumirlo
                if (speechSynthesis.paused) {
                    speechSynthesis.resume();
                } else {
                    // Si no hay utterance pausado, comenzar desde el bloque actual
                    speakBlock(currentBlockIndex);
                }
            }

            function stopReading() {
                speechSynthesis.cancel();
                finishReading();
            }

            function finishReading() {
                isReading = false;
                isPaused = false;
                currentBlockIndex = 0;
                lastSpokenIndex = -1;
                currentUtterance = null;
                updateButtons(false);
                updateProgress();
            }

        </script>        

        <script>

            var elem = document.documentElement;
            var fullscreenButton = document.getElementById("fullscreenButton");
            var fullscreenIcon = document.getElementById("fullscreenIcon");

            fullscreenButton.addEventListener("click", function() {
            if (document.fullscreenElement || document.mozFullScreenElement || document.webkitFullscreenElement || document.msFullscreenElement) {
                if (document.exitFullscreen) {
                document.exitFullscreen();
                } else if (document.mozCancelFullScreen) { /* Firefox */
                document.mozCancelFullScreen();
                } else if (document.webkitExitFullscreen) { /* Chrome, Safari and Opera */
                document.webkitExitFullscreen();
                } else if (document.msExitFullscreen) { /* IE/Edge */
                document.msExitFullscreen();
                }
            } else {
                if (elem.requestFullscreen) {
                elem.requestFullscreen();
                } else if (elem.mozRequestFullScreen) { /* Firefox */
                elem.mozRequestFullScreen();
                } else if (elem.webkitRequestFullscreen) { /* Chrome, Safari and Opera */
                elem.webkitRequestFullscreen();
                } else if (elem.msRequestFullscreen) { /* IE/Edge */
                elem.msRequestFullscreen();
                }
            }
            });

            document.addEventListener('fullscreenchange', (event) => {
            if (!document.fullscreenElement) {
                fullscreenIcon.innerHTML = '<path d="M5 5h5v5H5zM14 5h5v5h-5zM5 14h5v5H5zM14 14h5v5h-5z"/>';
            } else {
                fullscreenIcon.innerHTML = '<path d="M7 14H5v5h5v-2H7v-3zm-2-4h2V7h3V5H5v5zm12 7h-3v2h5v-5h-2v3zM14 5v2h3v3h2V5h-5z"/>';
            }
            });
        </script>

    </body>
    </html>