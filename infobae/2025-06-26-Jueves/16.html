<!DOCTYPE html>
    <html lang="es">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Cómo funciona la IA de Google que estudia el genoma humano y predice mutaciones en el ADN.</title>
        <style>
            body {
                max-width: 800px;
                margin: auto;
                padding: 5%;
            }
            .btnL {
                background: #d1d1d1;
                border-radius: 7px;
                padding: 18px;
                min-width: 100%;
                color: #000000;
                font-size: medium;
                min-height: 70px;
            }
            button {
                background-color: #d1d1d1;
                color: white;
                padding: 10px 20px;
                border: none;
                border-radius: 4px;
                cursor: pointer;
                margin: 5px;
            }
            button:disabled {
                background-color: #d1d1d1;
                cursor: not-available;
            }
            button:hover:not(:disabled) {
                background-color: #d1d1d1;
            }
            #voiceSelect {
                margin: 10px 0;
                padding: 5px;
            }
            .controls {
                margin: 10px 0;
            }

            #fullscreenButton {
                position: fixed;
                top: 20px;
                right: 20px;
                padding: 10px;
                background-color: transparent;
                border: none;
                cursor: pointer;
                border-radius: 5px;
            }

            #fullscreenIcon {
                width: 24px;
                height: 24px;
            }

        </style>
    </head>
    <body>
        <button id="fullscreenButton">
        <svg id="fullscreenIcon" viewBox="0 0 24 24" fill="currentColor">
            <path d="M5 5h5v5H5zM14 5h5v5h-5zM5 14h5v5H5zM14 14h5v5h-5z"/>
        </svg>
        </button>

        <div id="texto">
            <h1>Cómo funciona la IA de Google que estudia el genoma humano y predice mutaciones en el ADN.</h1>
            <p>Más de dos décadas después de que se completara el primer borrador del genoma humano, gran parte de su secuencia aún es un territorio inexplorado.</p><p>Aunque el mapa de los 3100 millones de letras del ADN humano fue publicado en 2003, comprender el funcionamiento real de ese código genético ha resultado mucho más complejo.</p><p>Ahora, un nuevo avance en inteligencia artificial promete cambiar ese panorama: se trata de AlphaGenome, el modelo desarrollado por Google DeepMind que busca traducir el lenguaje genético en información funcional y práctica para la biología y la medicina.</p><p>A diferencia de la parte del genoma que codifica proteínas, que representa solo el 2 %, la vasta región no codificante ha sido durante años una fuente de incertidumbre. En ese sector —la llamada “materia oscura” del genoma— se encuentran muchos de los elementos que regulan cuándo y cómo se activan los genes.</p><p>AlphaGenome fue diseñado justamente para abordar este terreno incierto. Mediante técnicas de aprendizaje automático y una arquitectura basada en transformadores, esta IA puede analizar hasta un millón de letras de ADN en una sola entrada y predecir miles de propiedades biológicas asociadas a esa secuencia.</p><p>Lo notable es que estas predicciones no se limitan a regiones codificantes. AlphaGenome puede detectar patrones en zonas lejanas de la secuencia que actúan como interruptores genéticos.</p><p>Y no solo identifica funciones, sino que evalúa cómo mutaciones puntuales en el ADN podrían alterar esos procesos.</p><p>Según los investigadores de DeepMind, el sistema predijo con éxito casos en los que una mutación activa anormalmente el gen TAL1, un evento que contribuye al desarrollo de leucemia linfoblástica aguda de células T. Este tipo de resultados entusiasma a la comunidad científica por el potencial que ofrece para entender el impacto de las variaciones genéticas en múltiples enfermedades.</p><p>“Por primera vez, hemos creado un modelo único que unifica muchos desafíos diferentes que vienen con la comprensión del genoma”, afirmó Pushmeet Kohli, vicepresidente de investigación de DeepMind.</p><p>Desde su presentación oficial, ayer 25 de junio, AlphaGenome fue puesto a disposición de universidades, laboratorios públicos y centros de salud que deseen explorar sus aplicaciones.</p><p>La llegada de AlphaGenome ocurre en un contexto donde la inteligencia artificial ya mostró avances disruptivos en ciencias de la vida. En 2020, Google presentó AlphaFold, un sistema que resolvió uno de los problemas más antiguos de la biología: predecir cómo una cadena de aminoácidos se pliega en una estructura tridimensional para formar una proteína.</p><p>Ese desarrollo derivó en la creación de Isomorphic Labs, una empresa dedicada al descubrimiento de fármacos, y en la obtención del Premio Nobel de Química en 2024 otorgado a los creadores de AlphaFold, John Jumper y Demis Hassabis, junto con David Baker.</p><p>Los galardonados explicaron en ese entonces que AlphaFold es un sistema de inteligencia artificial que predice cómo se pliegan las proteínas a partir de su secuencia de aminoácidos, resolviendo un problema que perduró durante décadas en la biología molecular. Jumper y Hassabis trabajan en Google DeepMind, donde lideraron el desarrollo de esta herramienta, mientras que Baker, bioquímico de la Universidad de Washington, fue premiado por sus contribuciones en el diseño computacional de proteínas. La Academia resaltó que estos aportes abren una nueva etapa en la medicina, la biotecnología y el medio ambiente.</p><p>Ahora, con AlphaGenome, la ambición es ampliar ese impacto desde las proteínas hacia el genoma completo.</p><p>Mientras que AlphaFold ofrecía una única respuesta estructural a partir de una secuencia proteica, AlphaGenome enfrenta una complejidad mayor.</p><p>Las secuencias de ADN no cumplen una sola función, sino que participan de múltiples procesos superpuestos. Un mismo fragmento puede atraer proteínas que regulan la transcripción, modificar la forma tridimensional del cromosoma o definir si un gen se activará o quedará en silencio. Captar esa diversidad de funciones en un solo modelo representa un salto en la interpretación genómica.</p><p>Anshul Kundaje, especialista en genómica computacional de la Universidad de Stanford, fue uno de los investigadores que accedió de forma anticipada al sistema. “Creo que es un gran avance. Es una auténtica mejora en prácticamente todos los modelos de secuenciación a función de vanguardia actuales”, aseguró.</p><p>La arquitectura del modelo se inspira en los mismos principios que sustentan los grandes modelos de lenguaje como GPT-4, aunque en este caso aplicados al “idioma” del ADN. Para entrenarlo, DeepMind utilizó datos de consorcios científicos como ENCODE, GTEx, 4D Nucleome y FANTOM5, que abarcan información genética y epigenética de cientos de tipos celulares humanos y de ratón.</p><p>Esa diversidad de datos permitió que AlphaGenome reconociera patrones funcionales más allá del contexto genético inmediato.</p><p>En términos prácticos, el modelo puede predecir dónde empiezan y terminan los genes en distintas células, cómo se empalman los fragmentos de ARN, dónde se unen las proteínas reguladoras o cuánto ARN se producirá. Además, su capacidad para comparar secuencias normales con mutadas ofrece una herramienta clave para evaluar el impacto de una variante genética antes de llevarla al laboratorio. Según DeepMind, AlphaGenome puede estimar en cuestión de segundos el efecto de una mutación sobre múltiples procesos moleculares.</p><p>Esa rapidez resulta particularmente útil en escenarios clínicos donde se analizan grandes volúmenes de datos genéticos. “Tenemos estos 3 mil millones de letras de ADN que conforman el genoma humano, pero cada persona es ligeramente diferente y no comprendemos del todo el efecto de esas diferencias. Esta es la herramienta más potente hasta la fecha para modelar esto”, explicó Caleb Lareau, biólogo computacional del Centro Oncológico Memorial Sloan Kettering.</p><p>Los biólogos suelen enfrentarse a conjuntos de datos que incluyen miles de variantes genéticas asociadas a una enfermedad. Determinar cuál de ellas tiene un efecto real sobre la salud requiere una enorme inversión en tiempo y recursos de laboratorio. Con AlphaGenome, muchas de esas pruebas podrían realizarse de forma virtual. Lareau señala que el modelo permitirá reducir las hipótesis que deben evaluarse en experimentos reales: “Recibirás una lista de variantes genéticas, pero luego quiero entender cuáles de ellas realmente tienen algún efecto y dónde puedo intervenir”.</p><p>Aunque AlphaGenome no fue diseñado para predecir rasgos individuales ni ascendencias personales, como los servicios comerciales de genómica, sí ofrece una aproximación detallada al funcionamiento de las variantes genéticas en términos moleculares. “No hemos diseñado ni validado AlphaGenome para la predicción del genoma personal, un desafío conocido para los modelos de IA”, aclaró Google en un comunicado.</p><p>Para casos clínicos complejos, como los cánceres raros con mutaciones poco documentadas, esta IA podría ofrecer pistas sobre qué cambios genéticos están detrás de la enfermedad. Julien Gagneur, profesor de medicina computacional en la Universidad Técnica de Múnich, señaló: “Una característica distintiva del cáncer es que mutaciones específicas en el ADN hacen que los genes incorrectos se expresen en el contexto equivocado. Este tipo de herramienta es fundamental para identificar cuáles alteran la expresión génica adecuada”.</p><p>Gagneur también considera que AlphaGenome podría ser útil para pacientes con enfermedades genéticas raras, cuyo diagnóstico muchas veces no se alcanza incluso después de decodificar su genoma. “Podemos obtener sus genomas, pero desconocemos qué alteraciones genéticas causan la enfermedad”, indicó. Para estos casos, el modelo podría aportar una nueva vía de investigación diagnóstica.</p><p>Además del ámbito clínico, algunos investigadores proyectan aplicaciones más ambiciosas. Desde diseñar genomas artificiales hasta desarrollar un laboratorio completamente virtual para ensayos farmacológicos, el potencial de estos modelos de IA todavía no conoce límites definidos.</p><p>“Mi sueño sería simular una célula virtual. Puede que AlphaGenome no modele la célula completa, pero está empezando a arrojar luz sobre la semántica más amplia del ADN”, dijo Demis Hassabis, director ejecutivo de Google DeepMind. Kohli coincide en que AlphaGenome representa un paso en ese camino.</p><p>Por el momento, la API de AlphaGenome estará disponible para instituciones académicas, laboratorios públicos y organismos de salud. DeepMind planea abrir el modelo a colaboraciones con gobiernos e industrias, aunque la versión para uso comercial todavía no está lista. La compañía también aseguró que compartirá detalles técnicos del modelo para facilitar su validación e integración en nuevas investigaciones.</p><p>Mientras tanto, los primeros resultados permiten anticipar un cambio de paradigma en la forma en que la ciencia aborda el genoma humano.</p><p>No se trata solo de observar letras, sino de empezar a comprender su significado en contexto. AlphaGenome propone justamente eso: un intento de leer el ADN con un nuevo tipo de inteligencia.</p><p>Temas Relacionados</p><p></p>
        </div>
        <br><br><br>
            <div style="display: none;">
                <label for="voiceSelect">Seleccionar voz:</label>
                <select id="voiceSelect"></select>
            </div>
            <div class="controls">
                <button onclick="startReading()" id="playButton">
                    🔊 Leer
                </button>
                <button onclick="pauseReading()" id="pauseButton" disabled style="display: none;">
                    ⏸️ Pausar
                </button>
                <button onclick="resumeReading()" id="resumeButton" disabled style="display: none;">
                    ▶️ Continuar
                </button>
                <button onclick="stopReading()" id="stopButton" disabled>
                    ⏹️ Detener
                </button>
            </div>
            <div id="progress" style="display: none;"></div>
        <br><br><br>
        <button class="btnL" onclick="compartir()">Compartir</button>
        <br><br><br>
        <button class="btnL" onclick="window.location.href='https://www.infobae.com/america/ciencia-america/2025/06/26/como-funciona-alphagenome-la-ia-de-google-que-estudia-el-genoma-humano-y-puede-predecir-mutaciones-en-el-adn/'">Ver en web original</button>
        <br><br><br>
        <!-- <button class="btnL" onclick="window.location.href='https://matenews.github.io/MateNews/'">Volver a la página principal</button>
        <br><br><br> -->


        <script>
            function compartir() {
            if (navigator.share) {
                navigator.share({
                title: 'Cómo funciona la IA de Google que estudia el genoma humano y predice mutaciones en el ADN.', // Opcional, pero recomendado     
                text: 'Cómo funciona la IA de Google que estudia el genoma humano y predice mutaciones en el ADN.',  // Opcional
                url: 'https://www.infobae.com/america/ciencia-america/2025/06/26/como-funciona-alphagenome-la-ia-de-google-que-estudia-el-genoma-humano-y-puede-predecir-mutaciones-en-el-adn/'
                })
                .then(() => console.log('Contenido compartido exitosamente'))
                .catch((error) => console.error('Error al compartir:', error));
            } else {
                // Código alternativo si la API Web Share no está disponible
                console.log("Web Share API no soportada");
                // Puedes usar aquí la opción 2 (botones personalizados con JavaScript) de mi respuesta anterior
            }
            }
        </script>


        <script>
            let speechSynthesis = window.speechSynthesis;
            let currentUtterance = null;
            let isPaused = false;
            let isReading = false;
            let textBlocks = [];
            let currentBlockIndex = 0;
            let lastSpokenIndex = 0;
            const BLOCK_SIZE = 800;

            function updateButtons(speaking) {
                document.getElementById('playButton').disabled = speaking;
                document.getElementById('pauseButton').disabled = !speaking;
                document.getElementById('resumeButton').disabled = !isPaused;
                document.getElementById('stopButton').disabled = !speaking;
            }

            function updateProgress() {
                const progressDiv = document.getElementById('progress');
                if (isReading) {
                    progressDiv.textContent = `Leyendo bloque ${currentBlockIndex + 1} de ${textBlocks.length}`;
                } else {
                    progressDiv.textContent = '';
                }
            }

            function splitIntoBlocks(text) {
                // Dividir el texto en oraciones usando puntuación común
                const sentences = text.replace(/([.!?])\s+/g, "$1|").split("|");

                let blocks = [];
                let currentBlock = '';

                sentences.forEach(sentence => {
                    // Si la oración es muy larga, dividirla en la coma más cercana al BLOCK_SIZE
                    if (sentence.length > BLOCK_SIZE) {
                        let subSentences = sentence.replace(/,\s+/g, ",|").split("|");
                        subSentences.forEach(subSentence => {
                            if (currentBlock.length + subSentence.length > BLOCK_SIZE) {
                                if (currentBlock) blocks.push(currentBlock.trim());
                                currentBlock = subSentence;
                            } else {
                                currentBlock += (currentBlock ? ' ' : '') + subSentence;
                            }
                        });
                    } else {
                        if (currentBlock.length + sentence.length > BLOCK_SIZE) {
                            blocks.push(currentBlock.trim());
                            currentBlock = sentence;
                        } else {
                            currentBlock += (currentBlock ? ' ' : '') + sentence;
                        }
                    }
                });

                if (currentBlock) blocks.push(currentBlock.trim());
                return blocks;
            }

            function speakBlock(index) {
                if (index >= textBlocks.length) {
                    isReading = false;
                    updateButtons(false);
                    updateProgress();
                    return;
                }

                currentUtterance = new SpeechSynthesisUtterance(textBlocks[index]);
                currentUtterance.rate = parseFloat(1.3);
                lastSpokenIndex = index;


                currentUtterance.onend = function() {
                    if (isReading && !isPaused) {
                        currentBlockIndex++;
                        updateProgress();
                        speakBlock(currentBlockIndex);
                    }
                };

                currentUtterance.onerror = function(event) {
                    console.error('Error en la lectura:', event);
                    isReading = false;
                    updateButtons(false);
                    updateProgress();
                };

                speechSynthesis.speak(currentUtterance);
            }

            function startReading() {
                const text = document.getElementById('texto').innerText;
                if (!text) return;

                // Detener cualquier lectura previa
                stop();

                // Preparar nueva lectura
                textBlocks = splitIntoBlocks(text);
                currentBlockIndex = 0;
                isReading = true;
                isPaused = false;

                updateButtons(true);
                updateProgress();
                speakBlock(currentBlockIndex);
            }

            function pause() {
                speechSynthesis.pause();
                isPaused = true;
                updateButtons(true);
            }

            function resume() {
                speechSynthesis.resume();
                isPaused = false;
                updateButtons(true);
            }

            function stop() {
                speechSynthesis.cancel();
                isReading = false;
                isPaused = false;
                currentBlockIndex = 0;
                updateButtons(false);
                updateProgress();
            }

            function pauseReading() {
                if (!isReading) return;

                speechSynthesis.pause();
                isPaused = true;
                isReading = false;
                updateButtons(true);
                updateProgress();
            }

            function resumeReading() {
                if (!isPaused) return;

                isPaused = false;
                isReading = true;

                // Si el utterance actual ya terminó, comenzar con el siguiente bloque
                if (lastSpokenIndex === currentBlockIndex) {
                    currentBlockIndex++;
                }

                updateButtons(true);
                updateProgress();

                // Si hay un utterance pausado, resumirlo
                if (speechSynthesis.paused) {
                    speechSynthesis.resume();
                } else {
                    // Si no hay utterance pausado, comenzar desde el bloque actual
                    speakBlock(currentBlockIndex);
                }
            }

            function stopReading() {
                speechSynthesis.cancel();
                finishReading();
            }

            function finishReading() {
                isReading = false;
                isPaused = false;
                currentBlockIndex = 0;
                lastSpokenIndex = -1;
                currentUtterance = null;
                updateButtons(false);
                updateProgress();
            }

        </script>        

        <script>

            var elem = document.documentElement;
            var fullscreenButton = document.getElementById("fullscreenButton");
            var fullscreenIcon = document.getElementById("fullscreenIcon");

            fullscreenButton.addEventListener("click", function() {
            if (document.fullscreenElement || document.mozFullScreenElement || document.webkitFullscreenElement || document.msFullscreenElement) {
                if (document.exitFullscreen) {
                document.exitFullscreen();
                } else if (document.mozCancelFullScreen) { /* Firefox */
                document.mozCancelFullScreen();
                } else if (document.webkitExitFullscreen) { /* Chrome, Safari and Opera */
                document.webkitExitFullscreen();
                } else if (document.msExitFullscreen) { /* IE/Edge */
                document.msExitFullscreen();
                }
            } else {
                if (elem.requestFullscreen) {
                elem.requestFullscreen();
                } else if (elem.mozRequestFullScreen) { /* Firefox */
                elem.mozRequestFullScreen();
                } else if (elem.webkitRequestFullscreen) { /* Chrome, Safari and Opera */
                elem.webkitRequestFullscreen();
                } else if (elem.msRequestFullscreen) { /* IE/Edge */
                elem.msRequestFullscreen();
                }
            }
            });

            document.addEventListener('fullscreenchange', (event) => {
            if (!document.fullscreenElement) {
                fullscreenIcon.innerHTML = '<path d="M5 5h5v5H5zM14 5h5v5h-5zM5 14h5v5H5zM14 14h5v5h-5z"/>';
            } else {
                fullscreenIcon.innerHTML = '<path d="M7 14H5v5h5v-2H7v-3zm-2-4h2V7h3V5H5v5zm12 7h-3v2h5v-5h-2v3zM14 5v2h3v3h2V5h-5z"/>';
            }
            });
        </script>

    </body>
    </html>