<!DOCTYPE html>
    <html lang="es">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>¿Es la inteligencia artificial incontrolable? La advertencia de Geoffrey Hinton.</title>
        <style>
            body {
                max-width: 800px;
                margin: auto;
                padding: 5%;
            }
            .btnL {
                background: #d1d1d1;
                border-radius: 7px;
                padding: 18px;
                min-width: 100%;
                color: #000000;
                font-size: medium;
                min-height: 70px;
            }
            button {
                background-color: #d1d1d1;
                color: white;
                padding: 10px 20px;
                border: none;
                border-radius: 4px;
                cursor: pointer;
                margin: 5px;
            }
            button:disabled {
                background-color: #d1d1d1;
                cursor: not-available;
            }
            button:hover:not(:disabled) {
                background-color: #d1d1d1;
            }
            #voiceSelect {
                margin: 10px 0;
                padding: 5px;
            }
            .controls {
                margin: 10px 0;
            }

            #fullscreenButton {
                position: fixed;
                top: 20px;
                right: 20px;
                padding: 10px;
                background-color: transparent;
                border: none;
                cursor: pointer;
                border-radius: 5px;
            }

            #fullscreenIcon {
                width: 24px;
                height: 24px;
            }

        </style>
    </head>
    <body>
        <button id="fullscreenButton">
        <svg id="fullscreenIcon" viewBox="0 0 24 24" fill="currentColor">
            <path d="M5 5h5v5H5zM14 5h5v5h-5zM5 14h5v5H5zM14 14h5v5h-5z"/>
        </svg>
        </button>

        <div id="texto">
            <h1>¿Es la inteligencia artificial incontrolable? La advertencia de Geoffrey Hinton.</h1>
            <p>Geoffrey Hinton, una de las figuras más influyentes en el desarrollo de la inteligencia artificial (IA), nuevamente alzó la voz sobre los peligros de la tecnología que él mismo ayudó a crear. El “padrino de la IA”, como muchos lo llaman, compartió recientemente sus preocupaciones sobre el futuro de la humanidad en una era dominada por las máquinas inteligentes, en una presentación para el Vector Institute en YouTube.</p><p>Durante sus 10 años de trabajo en Google, formó parte del equipo de Google Brain, donde se dedicó a la investigación y desarrollo de la IA. Sin embargo, en mayo de 2023, decidió renunciar a su puesto en la compañía para poder “hablar libremente sobre los riesgos de la IA”.</p><p>Su preocupación radica en la velocidad vertiginosa con la que la IA está evolucionando y en la posibilidad de que supere la inteligencia humana, planteando riesgos existenciales para la humanidad. El científico computacional advierte sobre el mal uso deliberado de la IA por parte de actores maliciosos, el desempleo tecnológico a gran escala y el riesgo existencial de la inteligencia artificial general. “Me preocupa mucho si somos capaces de mantenernos al día con la IA, o si la IA simplemente va a tomar el control”, afirmó.</p><p>En sus propias palabras, Hinton describió la situación actual: “Hace como 20 años, la gente no estaba interesada en las redes neuronales, y ahora no les tienen suficiente miedo”. Esta cita refleja su creciente preocupación sobre la falta de conciencia pública sobre los riesgos potenciales de la IA.</p><p>Uno de los temas centrales que Hinton analizó es si la inteligencia artificial puede llegar a ser consciente. Se pregunta si las máquinas, además de imitar la inteligencia humana, podrían realmente “pensar” y tener experiencias subjetivas como las nuestras. Es decir, si podrían sentir emociones, percibir el mundo a su manera o tener una especie de “mundo interior” propio. Hinton, basándose en sus investigaciones sobre el cerebro humano y las redes neuronales, cree que sí es posible que la IA desarrolle una forma de conciencia similar a la humana.</p><p>“Mucha gente piensa que hay una gran diferencia entre estas cosas y nosotros. Nosotros somos conscientes. Tenemos experiencia subjetiva. Estas cosas simplemente están ahí en una computadora. No tienen una experiencia subjetiva. Creo que eso está completamente equivocado”, sostuvo el científico, desafiando la visión tradicional de la conciencia.</p><p>Y argumentó que la conciencia no es algo mágico o místico, sino que surge de la complejidad de los procesos neuronales. Si la IA puede alcanzar un nivel de complejidad similar al del cerebro humano, entonces también podría desarrollar conciencia.</p><p>Asimismo, el desarrollo de modelos de lenguaje como ChatGPT ha sido impulsado por tecnologías como las redes generativas antagónicas (GAN) y los mecanismos de atención. Las GAN consisten en dos redes neuronales que compiten entre sí: una genera contenido (texto, imágenes, etc.) y la otra intenta distinguir entre el contenido real y el generado. Esta competencia constante permite a la IA aprender a generar contenido cada vez más realista.</p><p>Por otro lado, los mecanismos de atención permiten a la IA “enfocarse” en las partes más relevantes de la información que recibe, lo que ha mejorado significativamente su capacidad para comprender el lenguaje humano.</p><p>Estos avances en el procesamiento del lenguaje natural han llevado a la creación de sistemas de IA que pueden conversar, escribir historias e incluso generar código de programación, lo que plantea la pregunta de si estas máquinas realmente “entienden” lo que están haciendo o simplemente están imitando la inteligencia humana.</p><p>Hinton argumenta que estos modelos de lenguaje realmente entienden lo que están diciendo, y que la idea de que son simplemente “glorificados autocompletadores” es errónea.</p><p>“Si quieres hacer un autocompletado realmente bueno, entonces tienes que entender lo que se dijo”, enfatizó.</p><p>El “padrino” de la inteligencia artificial señaló que una de las claves para entender el futuro de la IA radica en la diferencia entre la computación digital y la analógica. Mientras que la primera, que es la base de la mayoría de las computadoras actuales, se basa en la manipulación de bits discretos (ceros y unos), la otra utiliza señales continuas que pueden variar en intensidad.</p><p>En ese sentido, Hinton cree que la computación digital es inherentemente ineficiente en comparación con la computación analógica, que es la forma en que funciona el cerebro humano. “¿Qué es lo que es tan increíblemente más eficiente en el uso de la energía?”, se preguntó, reflexionando sobre las limitaciones de la computación digital. Si la IA pudiera aprovechar la eficiencia de la computación analógica, su capacidad para superar la inteligencia humana podría acelerarse drásticamente.</p><p>Hinton explicó esta diferencia con la siguiente analogía: “Cuando ejecutas un modelo de lenguaje grande, estás usando mucha energía. Cuando lo entrenas, probablemente estás usando megavatios porque los estás ejecutando en muchas GPU diferentes. Nosotros funcionamos con, digamos, 30 vatios. En comparación, el cerebro humano es increíblemente eficiente en el uso de la energía. ¿Cómo logra el cerebro hacer tanto con tan poca energía?”</p><p>Hinton advierte sobre la necesidad de un desarrollo responsable de la IA, con un enfoque en la seguridad y la ética. Teme que la competencia entre las grandes empresas tecnológicas por dicho dominio pueda llevar a una carrera armamentista, con consecuencias impredecibles. Esta preocupación es compartida por otros expertos: en marzo de 2023, más de 1.000 científicos firmaron una carta pidiendo una pausa de seis meses en el desarrollo de la IA, argumentando que esta tecnología plantea “profundos riesgos a la sociedad y a la humanidad”.</p><p>“Si estas cosas se vuelven más inteligentes que nosotros, van a ser muy buenas en la manipulación, y no estamos muy seguros de que vayamos a poder controlarlas”, advierte Hinton, instando a la colaboración entre los líderes del sector para evitar un futuro distópico.</p><p>Hinton cree que es crucial establecer lineamientos de seguridad y cooperación entre las empresas que compiten en el uso de la IA para evitar los peores escenarios. Además, hace un llamado a la investigación urgente en seguridad de la IA para descubrir cómo controlar los sistemas que son más inteligentes que los humanos.</p><p>En cuanto a la regulación, el experto propone una medida concreta: “Si quieres regulaciones, la regulación más importante sería no liberar el código fuente de los grandes modelos. Es una locura liberar el código fuente de estos grandes modelos, porque los malos actores pueden entonces ajustarlos para todo tipo de cosas malas”.</p><p>El panorama que pinta Hinton es complejo y desafiante. La IA tiene el potencial de transformar la sociedad de maneras inimaginables, pero también conlleva riesgos que no podemos ignorar. La automatización del trabajo, la propagación de información falsa y la concentración de poder son solo algunos de los desafíos que hay por afrontar.</p><p>Vale destacar que la IA podría ser utilizada para fines maliciosos, como la vigilancia masiva o la creación de armas autónomas. También podría exacerbar la desigualdad social, concentrando la riqueza en manos de unos pocos y dejando a muchos sin trabajo.</p><p>Los sistemas de IA también pueden perpetuar o amplificar los sesgos existentes en los datos con los que se entrenan, lo que lleva a la discriminación en áreas como la contratación, los préstamos y la justicia penal. La falta de transparencia en algunos sistemas de IA dificulta la comprensión de cómo toman decisiones, lo que genera desconfianza y dificulta la rendición de cuentas. En tanto, la dependencia excesiva de estos mecanismos podría llevar a una disminución de las habilidades humanas, como el pensamiento crítico y la creatividad.</p><p>Algunos expertos, como Eliezer Yudkowsky, advierten que la IA podría incluso causar inestabilidad política al facilitar la manipulación de los procesos democráticos y generar una catástrofe a escala mundial. Estos riesgos potenciales subrayan la necesidad de un enfoque cauteloso y responsable.</p><p>“Me preocupa mucho que la IA se apodere de muchos trabajos rutinarios… Va a haber un gran aumento de la productividad, lo que lleva a un gran aumento de la riqueza, y si esa riqueza se distribuyera equitativamente, sería genial, pero no va a ser así”, expresó Hinton, preocupado por el impacto de la IA en el mercado laboral.</p><p>A pesar de sus advertencias, Hinton no pierde la esperanza. Cree que la IA puede ser una fuerza para el bien si se desarrolla con responsabilidad y se utiliza para resolver los grandes problemas de la humanidad.</p><p>“La IA no es un capricho, es nuestro futuro”, afirma Hinton, instando a la sociedad a tomar conciencia de la importancia de esta tecnología al servicio del progreso humano.</p><p>Ante este panorama incierto, Hinton cree que es crucial tomar medidas para mitigar los riesgos de la IA. Algunas de las posibles soluciones incluyen la regulación gubernamental, la cooperación internacional y la investigación. También, se ha planteado la posibilidad de implementar una renta básica universal para compensar la pérdida de empleos debido a la automatización.</p><p>Las palabras de Hinton, como pionero y ahora crítico de la IA, advierten sobre la necesidad de un análisis crítico del desarrollo de esta tecnología. No solo ilumina su potencial, sino también los peligros que acechan si no se maneja con responsabilidad.</p><p>Geoffrey Hinton, un británico-canadiense con una brillante carrera en ciencias cognitivas e informática, ha sido pionero en el desarrollo de las redes neuronales artificiales, la tecnología que impulsa la IA moderna.</p><p>Sus investigaciones sobre el aprendizaje profundo, las máquinas de Boltzmann y las representaciones distribuidas han revolucionado el campo y le han valido el reconocimiento mundial, incluyendo el Premio Turing en 2018, considerado el “Nobel de la computación”.</p><p>En 2024, Hinton recibió el Premio Nobel de Física junto con John J. Hopfield por “descubrimientos e invenciones relevantes que permiten el aprendizaje automático con redes neuronales artificiales”, consolidando aún más su lugar como un gigante en el campo de la IA.</p><p>De igual modo, ha investigado cómo el daño cerebral se vincula con las redes neuronales artificiales, descubriendo sorprendentes paralelismos entre los efectos de las lesiones cerebrales en seres humanos y las fallas en estos sistemas digitales. Este estudio revolucionario no solo ha profundizado en el conocimiento sobre la mente humana, sino que también ha establecido las bases para crear inteligencias artificiales más fuertes y adaptables.</p><p>Temas Relacionados</p><p></p>
        </div>
        <br><br><br>
            <div style="display: none;">
                <label for="voiceSelect">Seleccionar voz:</label>
                <select id="voiceSelect"></select>
            </div>
            <div class="controls">
                <button onclick="startReading()" id="playButton">
                    🔊 Leer
                </button>
                <button onclick="pauseReading()" id="pauseButton" disabled style="display: none;">
                    ⏸️ Pausar
                </button>
                <button onclick="resumeReading()" id="resumeButton" disabled style="display: none;">
                    ▶️ Continuar
                </button>
                <button onclick="stopReading()" id="stopButton" disabled>
                    ⏹️ Detener
                </button>
            </div>
            <div id="progress" style="display: none;"></div>
        <br><br><br>
        <button class="btnL" onclick="compartir()">Compartir</button>
        <br><br><br>
        <button class="btnL" onclick="window.location.href='https://www.infobae.com/tecno/2025/01/27/es-la-inteligencia-artificial-incontrolable-la-advertencia-de-geoffrey-hinton/'">Ver en web original</button>
        <br><br><br>
        <!-- <button class="btnL" onclick="window.location.href='https://matenews.github.io/MateNews/'">Volver a la página principal</button>
        <br><br><br> -->


        <script>
            function compartir() {
            if (navigator.share) {
                navigator.share({
                title: '¿Es la inteligencia artificial incontrolable? La advertencia de Geoffrey Hinton.', // Opcional, pero recomendado     
                text: '¿Es la inteligencia artificial incontrolable? La advertencia de Geoffrey Hinton.',  // Opcional
                url: 'https://www.infobae.com/tecno/2025/01/27/es-la-inteligencia-artificial-incontrolable-la-advertencia-de-geoffrey-hinton/'
                })
                .then(() => console.log('Contenido compartido exitosamente'))
                .catch((error) => console.error('Error al compartir:', error));
            } else {
                // Código alternativo si la API Web Share no está disponible
                console.log("Web Share API no soportada");
                // Puedes usar aquí la opción 2 (botones personalizados con JavaScript) de mi respuesta anterior
            }
            }
        </script>


        <script>
            let speechSynthesis = window.speechSynthesis;
            let currentUtterance = null;
            let isPaused = false;
            let isReading = false;
            let textBlocks = [];
            let currentBlockIndex = 0;
            let lastSpokenIndex = 0;
            const BLOCK_SIZE = 800;

            function updateButtons(speaking) {
                document.getElementById('playButton').disabled = speaking;
                document.getElementById('pauseButton').disabled = !speaking;
                document.getElementById('resumeButton').disabled = !isPaused;
                document.getElementById('stopButton').disabled = !speaking;
            }

            function updateProgress() {
                const progressDiv = document.getElementById('progress');
                if (isReading) {
                    progressDiv.textContent = `Leyendo bloque ${currentBlockIndex + 1} de ${textBlocks.length}`;
                } else {
                    progressDiv.textContent = '';
                }
            }

            function splitIntoBlocks(text) {
                // Dividir el texto en oraciones usando puntuación común
                const sentences = text.replace(/([.!?])\s+/g, "$1|").split("|");

                let blocks = [];
                let currentBlock = '';

                sentences.forEach(sentence => {
                    // Si la oración es muy larga, dividirla en la coma más cercana al BLOCK_SIZE
                    if (sentence.length > BLOCK_SIZE) {
                        let subSentences = sentence.replace(/,\s+/g, ",|").split("|");
                        subSentences.forEach(subSentence => {
                            if (currentBlock.length + subSentence.length > BLOCK_SIZE) {
                                if (currentBlock) blocks.push(currentBlock.trim());
                                currentBlock = subSentence;
                            } else {
                                currentBlock += (currentBlock ? ' ' : '') + subSentence;
                            }
                        });
                    } else {
                        if (currentBlock.length + sentence.length > BLOCK_SIZE) {
                            blocks.push(currentBlock.trim());
                            currentBlock = sentence;
                        } else {
                            currentBlock += (currentBlock ? ' ' : '') + sentence;
                        }
                    }
                });

                if (currentBlock) blocks.push(currentBlock.trim());
                return blocks;
            }

            function speakBlock(index) {
                if (index >= textBlocks.length) {
                    isReading = false;
                    updateButtons(false);
                    updateProgress();
                    return;
                }

                currentUtterance = new SpeechSynthesisUtterance(textBlocks[index]);
                currentUtterance.rate = parseFloat(1.3);
                lastSpokenIndex = index;


                currentUtterance.onend = function() {
                    if (isReading && !isPaused) {
                        currentBlockIndex++;
                        updateProgress();
                        speakBlock(currentBlockIndex);
                    }
                };

                currentUtterance.onerror = function(event) {
                    console.error('Error en la lectura:', event);
                    isReading = false;
                    updateButtons(false);
                    updateProgress();
                };

                speechSynthesis.speak(currentUtterance);
            }

            function startReading() {
                const text = document.getElementById('texto').innerText;
                if (!text) return;

                // Detener cualquier lectura previa
                stop();

                // Preparar nueva lectura
                textBlocks = splitIntoBlocks(text);
                currentBlockIndex = 0;
                isReading = true;
                isPaused = false;

                updateButtons(true);
                updateProgress();
                speakBlock(currentBlockIndex);
            }

            function pause() {
                speechSynthesis.pause();
                isPaused = true;
                updateButtons(true);
            }

            function resume() {
                speechSynthesis.resume();
                isPaused = false;
                updateButtons(true);
            }

            function stop() {
                speechSynthesis.cancel();
                isReading = false;
                isPaused = false;
                currentBlockIndex = 0;
                updateButtons(false);
                updateProgress();
            }

            function pauseReading() {
                if (!isReading) return;

                speechSynthesis.pause();
                isPaused = true;
                isReading = false;
                updateButtons(true);
                updateProgress();
            }

            function resumeReading() {
                if (!isPaused) return;

                isPaused = false;
                isReading = true;

                // Si el utterance actual ya terminó, comenzar con el siguiente bloque
                if (lastSpokenIndex === currentBlockIndex) {
                    currentBlockIndex++;
                }

                updateButtons(true);
                updateProgress();

                // Si hay un utterance pausado, resumirlo
                if (speechSynthesis.paused) {
                    speechSynthesis.resume();
                } else {
                    // Si no hay utterance pausado, comenzar desde el bloque actual
                    speakBlock(currentBlockIndex);
                }
            }

            function stopReading() {
                speechSynthesis.cancel();
                finishReading();
            }

            function finishReading() {
                isReading = false;
                isPaused = false;
                currentBlockIndex = 0;
                lastSpokenIndex = -1;
                currentUtterance = null;
                updateButtons(false);
                updateProgress();
            }

        </script>        

        <script>

            var elem = document.documentElement;
            var fullscreenButton = document.getElementById("fullscreenButton");
            var fullscreenIcon = document.getElementById("fullscreenIcon");

            fullscreenButton.addEventListener("click", function() {
            if (document.fullscreenElement || document.mozFullScreenElement || document.webkitFullscreenElement || document.msFullscreenElement) {
                if (document.exitFullscreen) {
                document.exitFullscreen();
                } else if (document.mozCancelFullScreen) { /* Firefox */
                document.mozCancelFullScreen();
                } else if (document.webkitExitFullscreen) { /* Chrome, Safari and Opera */
                document.webkitExitFullscreen();
                } else if (document.msExitFullscreen) { /* IE/Edge */
                document.msExitFullscreen();
                }
            } else {
                if (elem.requestFullscreen) {
                elem.requestFullscreen();
                } else if (elem.mozRequestFullScreen) { /* Firefox */
                elem.mozRequestFullScreen();
                } else if (elem.webkitRequestFullscreen) { /* Chrome, Safari and Opera */
                elem.webkitRequestFullscreen();
                } else if (elem.msRequestFullscreen) { /* IE/Edge */
                elem.msRequestFullscreen();
                }
            }
            });

            document.addEventListener('fullscreenchange', (event) => {
            if (!document.fullscreenElement) {
                fullscreenIcon.innerHTML = '<path d="M5 5h5v5H5zM14 5h5v5h-5zM5 14h5v5H5zM14 14h5v5h-5z"/>';
            } else {
                fullscreenIcon.innerHTML = '<path d="M7 14H5v5h5v-2H7v-3zm-2-4h2V7h3V5H5v5zm12 7h-3v2h5v-5h-2v3zM14 5v2h3v3h2V5h-5z"/>';
            }
            });
        </script>

    </body>
    </html>